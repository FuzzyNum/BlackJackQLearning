{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\")\n",
    "import pygame\n",
    "import moviepy\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import seaborn\n",
    "from tqdm import tqdm #progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt #drawing plots\n",
    "from matplotlib.patches import Patch #draw shapes\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "env=gym.make(\"Taxi-v3\",render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "done=False\n",
    "observation, info=env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "action =env.action_space.sample()\n",
    "observation,reward,terminated,truncated,info =env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class TaxiAgent:\n",
    "    def __init__(self, learning_rate:float,initial_epsilon:float,epsilon_decay:float,final_epsilon:float,discount_factor:float = 0.95):\n",
    "        #Initialize RL agent with empty dictionary of state-action values, learning rate, epsilon.\n",
    "        #discount_factor: the discount factor for computing the Q-value.\n",
    "        self.q_values= defaultdict(lambda:np.zeros(env.action_space.n))\n",
    "        self.lr=learning_rate\n",
    "        self.discount_factor=discount_factor\n",
    "        self.epsilon=initial_epsilon\n",
    "        self.epsilon_decay=epsilon_decay\n",
    "        self.final_epsilon=final_epsilon\n",
    "        self.training_error=[]\n",
    "    def get_action(self, obs)->int:\n",
    "        if np.random.random()<self.epsilon:\n",
    "            return env.action_space.sample()\n",
    "        else:\n",
    "            return int(np.argmax(self.q_values[obs]))\n",
    "    def update(self, obs:int, action:int, reward:float, termianted:bool, next_obs:int)->int:\n",
    "        future_q_value=0\n",
    "        if not terminated:\n",
    "            future_q_value=np.max(self.q_values[next_obs])\n",
    "        temporal_difference= (reward+self.discount_factor*future_q_value-self.q_values[obs][action])\n",
    "        self.q_values[obs][action]=self.q_values[obs][action]+self.lr*temporal_difference\n",
    "        self.training_error.append(temporal_difference)\n",
    "    def decay_epsilon(self):\n",
    "        self.epsilon=max(self.final_epsilon, self.epsilon-self.epsilon_decay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "n_episodes=10000\n",
    "start_epsilon=1.0\n",
    "epsilon_decay= start_epsilon/(n_episodes/2)\n",
    "final_epsilon=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "agent = TaxiAgent(\n",
    "    learning_rate=learning_rate,\n",
    "    initial_epsilon=start_epsilon,\n",
    "    epsilon_decay=epsilon_decay,\n",
    "    final_epsilon=final_epsilon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "env=gym.wrappers.RecordEpisodeStatistics(env, deque_size=n_episodes)\n",
    "env= gym.wrappers.RecordVideo(env, video_folder=\"taxi_agent\", episode_trigger=lambda x: x%1000==0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(n_episodes)):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = int(agent.get_action(obs))\n",
    "        next_obs, reward, terminated, truncated, infos = env.step(action)\n",
    "\n",
    "        agent.update(obs, action, reward, terminated, next_obs)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        obs = next_obs\n",
    "\n",
    "    agent.decay_epsilon()\n",
    "env.close()\n",
    "\n",
    "rolling_length=500\n",
    "fig, axs= plt.subplots(ncols=3, figsize=(12,5))\n",
    "axs[0].set_title(\"Episode rewards\")\n",
    "reward_moving_average=(np.convolve(np.array(env.return_queue).flatten(), np.ones(rolling_length), mode=\"same\")/rolling_length)\n",
    "axs[0].plot(range(len(reward_moving_average)), reward_moving_average)\n",
    "axs[1].set_title(\"Episode Lengths\")\n",
    "length_moving_average=(np.convolve(np.array(env.length_queue).flatten(), np.ones(rolling_length), mode=\"same\")/rolling_length)\n",
    "axs[1].plot(range(len(length_moving_average)),length_moving_average)\n",
    "training_error_moving_average=(np.convolve(np.array(agent.training_error).flatten(), np.ones(rolling_length), mode=\"same\")/rolling_length)\n",
    "axs[2].plot(range(len(training_error_moving_average)), training_error_moving_average)\n",
    "axs[2].set_title(\"Episode Error\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
